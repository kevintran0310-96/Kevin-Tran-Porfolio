{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqtra0027\u001b[0m (\u001b[33mailecs-lab-students\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login to Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/Pycharm Project/DUTA10K/wandb/run-20250523_075008-cnsss7w2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20ver%201%20%28binary%20classification%29/runs/cnsss7w2' target=\"_blank\">denim-plant-4</a></strong> to <a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20ver%201%20%28binary%20classification%29' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20ver%201%20%28binary%20classification%29' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20ver%201%20%28binary%20classification%29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20ver%201%20%28binary%20classification%29/runs/cnsss7w2' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20ver%201%20%28binary%20classification%29/runs/cnsss7w2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a new Weights & Biases run for experiment tracking\n",
    "run = wandb.init(\n",
    "    project='Using BERT to classify illicit content on online marketplace ver 1 (binary classification)', \n",
    "    job_type=\"training\", \n",
    "    resume=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings\n",
    "SEED = 500\n",
    "FILE_PATH = \"DUTA10K_final.jsonl\"\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "MAX_LEN = 128\n",
    "TEST_SET_SIZE = 0.1\n",
    "VALIDATION_SET_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4178 records.\n",
      "Using 4178 records after dropping NA.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from a JSONL file\n",
    "try:\n",
    "    df = pd.read_json(\"DUTA10K_final.jsonl\", lines=True)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {FILE_PATH} was not found. Please check the path.\")\n",
    "    exit()\n",
    "except ValueError as e:\n",
    "    print(f\"Error reading JSONL file: {e}. Ensure it's a valid JSONL format.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loaded {len(df)} records.\")\n",
    "df = df.dropna(subset=['text', 'label'])\n",
    "df['label'] = df['label'].astype(int)\n",
    "print(f\"Using {len(df)} records after dropping NA.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 3342\n",
      "Validation samples: 418\n",
      "Test samples: 418\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)\n",
    "\n",
    "# Split Data into Train, Validation, and Test DataFrames\n",
    "# First, split into train_val_df and test_df\n",
    "train_val_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SET_SIZE,\n",
    "    random_state=SEED,\n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "# Then, split train_val_df into train_df and eval_df\n",
    "train_df, eval_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=VALIDATION_SET_SIZE / (1 - TEST_SET_SIZE),\n",
    "    random_state=SEED,\n",
    "    stratify=train_val_df['label']\n",
    ")\n",
    "\n",
    "# Reset indices of the split DataFrames\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "eval_df = eval_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(eval_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")\n",
    "\n",
    "# Convert DataFrames to Hugging Face Dataset objects\n",
    "train_dataset_hf = Dataset.from_pandas(train_df[['text', 'label']])\n",
    "eval_dataset_hf = Dataset.from_pandas(eval_df[['text', 'label']])\n",
    "test_dataset_hf = Dataset.from_pandas(test_df[['text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6ae32a6e514fb8bdcb1e10f12158b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3342 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0571240fd87445a9a52d6520e3c833d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffcf2821f7041db895b1c5c323a2069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize Datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "tokenized_train_dataset = train_dataset_hf.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset_hf.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset_hf.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns([\"text\"])\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.remove_columns([\"text\"])\n",
    "tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"text\"])\n",
    "\n",
    "tokenized_train_dataset.set_format(\"torch\")\n",
    "tokenized_eval_dataset.set_format(\"torch\")\n",
    "tokenized_test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT Model (Base Model)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=2, # For binary classification\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicitly selected LoRA target modules for BERT: ['query', 'key', 'value', 'dense']\n"
     ]
    }
   ],
   "source": [
    "# Identify target modules for LoRA adaptation\n",
    "target_modules = []\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        # Get the last part of the name (e.g., 'query', 'dense')\n",
    "        target_modules.append(name.split('.')[-1])\n",
    "\n",
    "# Refine target_modules to specific linear layers relevant for BERT LoRA\n",
    "# This list is based on common practice for BERT models in PEFT\n",
    "target_modules = [\"query\", \"key\", \"value\", \"dense\"]\n",
    "encoder_linear_layers = []\n",
    "for name, module in model.bert.named_modules(): # Look inside the 'bert' part\n",
    "    if isinstance(module, nn.Linear):\n",
    "        encoder_linear_layers.append(name)\n",
    "print(f\"Explicitly selected LoRA target modules for BERT: {target_modules}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters after LoRA adaptation:\n",
      "trainable params: 10,716,674 || all params: 120,200,452 || trainable%: 8.9157\n"
     ]
    }
   ],
   "source": [
    "# Configure LoRA (Low-Rank Adaptation)\n",
    "lora_config = LoraConfig(\n",
    "    r=64,\n",
    "    lora_alpha=32,\n",
    "    target_modules=target_modules, # Using the refined list for BERT\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS, # For sequence classification\n",
    ")\n",
    "\n",
    "# Get the PEFT (Parameter-Efficient Fine-Tuning) model by applying LoRA config\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(\"Trainable parameters after LoRA adaptation:\")\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Enable gradient checkpointing to save memory\n",
    "if hasattr(model, \"gradient_checkpointing_enable\"):\n",
    "    model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Metrics Computation Function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary', zero_division=0)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert_binary_ver1\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True if torch.cuda.is_available() else False,\n",
    "    logging_steps=50,\n",
    "    report_to=[\"wandb\"],\n",
    "    seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2833885/1646960990.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 18:58, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.460736</td>\n",
       "      <td>0.811005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.417362</td>\n",
       "      <td>0.846890</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.189873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>0.406269</td>\n",
       "      <td>0.849282</td>\n",
       "      <td>0.336842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.369400</td>\n",
       "      <td>0.393243</td>\n",
       "      <td>0.839713</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.202532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.390453</td>\n",
       "      <td>0.830144</td>\n",
       "      <td>0.310680</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.202532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.342200</td>\n",
       "      <td>0.389488</td>\n",
       "      <td>0.832536</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.215190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>0.389597</td>\n",
       "      <td>0.832536</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.215190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3336, training_loss=0.4091828100972896, metrics={'train_runtime': 1138.7582, 'train_samples_per_second': 23.478, 'train_steps_per_second': 2.93, 'total_flos': 1974093912496128.0, 'train_loss': 0.4091828100972896, 'epoch': 7.981448234590066})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁██▆▄▅▅▅</td></tr><tr><td>eval/f1</td><td>▁███▇███</td></tr><tr><td>eval/loss</td><td>█▄▃▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁██▇▆▆▆▆</td></tr><tr><td>eval/recall</td><td>▁▇██████</td></tr><tr><td>eval/runtime</td><td>▃█▁▆▇▆▄▅</td></tr><tr><td>eval/samples_per_second</td><td>▆▁█▃▂▃▅▄</td></tr><tr><td>eval/steps_per_second</td><td>▆▁█▃▂▃▅▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>train/grad_norm</td><td>▆▄▂▄▃▆▄▂▁▂▃▆▃▂▃▂▄▃▁▁▄▄▄▁▁█▃▃▅▄▂▆▇▂▄▂▂▁▅▄</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▄▄▃▃▃▃▅▂▃▂▂▂▃▃▃▁▃▃▁▃▂▃▁▂▂▃▃▁▂▂▁▂▂▃▂▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.83254</td></tr><tr><td>eval/f1</td><td>0.32692</td></tr><tr><td>eval/loss</td><td>0.3896</td></tr><tr><td>eval/precision</td><td>0.68</td></tr><tr><td>eval/recall</td><td>0.21519</td></tr><tr><td>eval/runtime</td><td>11.027</td></tr><tr><td>eval/samples_per_second</td><td>37.907</td></tr><tr><td>eval/steps_per_second</td><td>37.907</td></tr><tr><td>total_flos</td><td>1974093912496128.0</td></tr><tr><td>train/epoch</td><td>7.98145</td></tr><tr><td>train/global_step</td><td>3336</td></tr><tr><td>train/grad_norm</td><td>3.68898</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.379</td></tr><tr><td>train_loss</td><td>0.40918</td></tr><tr><td>train_runtime</td><td>1138.7582</td></tr><tr><td>train_samples_per_second</td><td>23.478</td></tr><tr><td>train_steps_per_second</td><td>2.93</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-spaceship-3</strong> at: <a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20ver%201%20%28binary%20classification%29/runs/0rhje2t5' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20ver%201%20%28binary%20classification%29/runs/0rhje2t5</a><br> View project at: <a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20ver%201%20%28binary%20classification%29' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20ver%201%20%28binary%20classification%29</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250523_060120-0rhje2t5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finish the Weights & Biases run\n",
    "wandb.finish()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert_binary_ver1/tokenizer_config.json',\n",
       " 'bert_binary_ver1/special_tokens_map.json',\n",
       " 'bert_binary_ver1/vocab.txt',\n",
       " 'bert_binary_ver1/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model and tokenizer\n",
    "trainer.save_model(\"bert_binary_ver1\")\n",
    "tokenizer.save_pretrained(\"bert_binary_ver1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the fine-tuned LoRA model on the TEST set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Set Evaluation Results (LoRA Multi-class) ===\n",
      "  accuracy: 0.8373\n",
      "  f1: 0.2444\n",
      "  precision: 1.0000\n",
      "  recall: 0.1392\n",
      "\n",
      "=== Detailed Classification Report on Test Set (LoRA) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non-illicit     0.8329    1.0000    0.9088       339\n",
      "     illicit     1.0000    0.1392    0.2444        79\n",
      "\n",
      "    accuracy                         0.8373       418\n",
      "   macro avg     0.9165    0.5696    0.5766       418\n",
      "weighted avg     0.8645    0.8373    0.7833       418\n",
      "\n",
      "\n",
      "=== Confusion Matrix on Test Set (LoRA) ===\n",
      "[[339   0]\n",
      " [ 68  11]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model on the Test Set\n",
    "print(\"\\nEvaluating the fine-tuned LoRA model on the TEST set...\")\n",
    "test_predictions_output = trainer.predict(tokenized_test_dataset)\n",
    "test_metrics = compute_metrics((test_predictions_output.predictions, test_predictions_output.label_ids))\n",
    "\n",
    "print(\"\\n=== Test Set Evaluation Results (LoRA Multi-class) ===\")\n",
    "for key, value in test_metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n=== Detailed Classification Report on Test Set (LoRA) ===\")\n",
    "y_test_preds = np.argmax(test_predictions_output.predictions, axis=-1)\n",
    "y_test_true = test_predictions_output.label_ids\n",
    "target_names = ['non-illicit', 'illicit']\n",
    "print(classification_report(y_test_true, y_test_preds, target_names=target_names, digits=4, zero_division=0))\n",
    "print(\"\\n=== Confusion Matrix on Test Set (LoRA) ===\")\n",
    "print(confusion_matrix(y_test_true, y_test_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
