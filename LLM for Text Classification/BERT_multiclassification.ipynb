{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqtra0027\u001b[0m (\u001b[33mailecs-lab-students\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login to Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/Pycharm Project/DUTA10K/wandb/run-20250523_015656-c6c4wsy7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29/runs/c6c4wsy7' target=\"_blank\">serene-snowball-3</a></strong> to <a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29/runs/c6c4wsy7' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29/runs/c6c4wsy7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a new Weights & Biases run for experiment tracking\n",
    "run = wandb.init(\n",
    "    project='Using BERT to classify illicit content on online marketplace (multiclass classification)', \n",
    "    job_type=\"training\", \n",
    "    resume=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration settings\n",
    "SEED = 500\n",
    "FILE_PATH = \"DUTA10K_final.jsonl\"\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "MAX_LEN = 128\n",
    "TEST_SET_SIZE = 0.1\n",
    "VALIDATION_SET_SIZE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Random Seeds\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4178 records.\n",
      "Using 4178 records after dropping NA from text/category.\n",
      "Number of unique classes: 40\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from a JSONL file\n",
    "try:\n",
    "    df = pd.read_json(\"DUTA10K_final.jsonl\", lines=True)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {FILE_PATH} was not found. Please check the path.\")\n",
    "    exit()\n",
    "except ValueError as e:\n",
    "    print(f\"Error reading JSONL file: {e}. Ensure it's a valid JSONL format.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Loaded {len(df)} records.\")\n",
    "\n",
    "df = df.dropna(subset=['text', 'category'])\n",
    "print(f\"Using {len(df)} records after dropping NA from text/category.\")\n",
    "\n",
    "# Encode Labels (Multi-class)\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['category']) # Use 'label' as the standard column name for Trainer\n",
    "num_labels = len(label_encoder.classes_)\n",
    "id2label = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "label2id = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "\n",
    "print(f\"Number of unique classes: {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 3342\n",
      "Validation samples: 418\n",
      "Test samples: 418\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT Tokenizer \n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME, do_lower_case=True)\n",
    "\n",
    "# Split Data into Train, Validation, and Test DataFrames \n",
    "# Stratify by the new integer 'label' column\n",
    "train_val_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SET_SIZE,\n",
    "    random_state=SEED,\n",
    "    # stratify=df['label'] # Stratify based on the encoded labels\n",
    ")\n",
    "\n",
    "train_df, eval_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=VALIDATION_SET_SIZE / (1 - TEST_SET_SIZE),\n",
    "    random_state=SEED,\n",
    "    # stratify=train_val_df['label'] # Stratify based on the encoded labels\n",
    ")\n",
    "\n",
    "# Reset indices of the split DataFrames\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "eval_df = eval_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(eval_df)}\")\n",
    "print(f\"Test samples: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896e4f1c37c744fd9a5bbe59501991bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3342 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e266a9016ec481389694e1afe64f049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec72e29916d45be8b508a72d97dfde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert DataFrames to Hugging Face Dataset objects \n",
    "# Ensure 'label' column (the encoded one) is used\n",
    "train_dataset_hf = Dataset.from_pandas(train_df[['text', 'label']])\n",
    "eval_dataset_hf = Dataset.from_pandas(eval_df[['text', 'label']])\n",
    "test_dataset_hf = Dataset.from_pandas(test_df[['text', 'label']])\n",
    "\n",
    "# Tokenize Datasets\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "tokenized_train_dataset = train_dataset_hf.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset_hf.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset_hf.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train_dataset = tokenized_train_dataset.remove_columns([\"text\"])\n",
    "tokenized_eval_dataset = tokenized_eval_dataset.remove_columns([\"text\"])\n",
    "tokenized_test_dataset = tokenized_test_dataset.remove_columns([\"text\"])\n",
    "\n",
    "tokenized_train_dataset.set_format(\"torch\")\n",
    "tokenized_eval_dataset.set_format(\"torch\")\n",
    "tokenized_test_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Create model using the custom implementation\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels, # Set to the number of unique categories\n",
    "    id2label=id2label,     # Pass mapping\n",
    "    label2id=label2id,     # Pass mapping\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined LoRA target modules for BERT (full names within model.bert): ['encoder.layer.0.attention.output.dense', 'encoder.layer.0.attention.self.key', 'encoder.layer.0.attention.self.query', 'encoder.layer.0.attention.self.value', 'encoder.layer.0.intermediate.dense', 'encoder.layer.0.output.dense', 'encoder.layer.1.attention.output.dense', 'encoder.layer.1.attention.self.key', 'encoder.layer.1.attention.self.query', 'encoder.layer.1.attention.self.value', 'encoder.layer.1.intermediate.dense', 'encoder.layer.1.output.dense', 'encoder.layer.10.attention.output.dense', 'encoder.layer.10.attention.self.key', 'encoder.layer.10.attention.self.query', 'encoder.layer.10.attention.self.value', 'encoder.layer.10.intermediate.dense', 'encoder.layer.10.output.dense', 'encoder.layer.11.attention.output.dense', 'encoder.layer.11.attention.self.key', 'encoder.layer.11.attention.self.query', 'encoder.layer.11.attention.self.value', 'encoder.layer.11.intermediate.dense', 'encoder.layer.11.output.dense', 'encoder.layer.2.attention.output.dense', 'encoder.layer.2.attention.self.key', 'encoder.layer.2.attention.self.query', 'encoder.layer.2.attention.self.value', 'encoder.layer.2.intermediate.dense', 'encoder.layer.2.output.dense', 'encoder.layer.3.attention.output.dense', 'encoder.layer.3.attention.self.key', 'encoder.layer.3.attention.self.query', 'encoder.layer.3.attention.self.value', 'encoder.layer.3.intermediate.dense', 'encoder.layer.3.output.dense', 'encoder.layer.4.attention.output.dense', 'encoder.layer.4.attention.self.key', 'encoder.layer.4.attention.self.query', 'encoder.layer.4.attention.self.value', 'encoder.layer.4.intermediate.dense', 'encoder.layer.4.output.dense', 'encoder.layer.5.attention.output.dense', 'encoder.layer.5.attention.self.key', 'encoder.layer.5.attention.self.query', 'encoder.layer.5.attention.self.value', 'encoder.layer.5.intermediate.dense', 'encoder.layer.5.output.dense', 'encoder.layer.6.attention.output.dense', 'encoder.layer.6.attention.self.key', 'encoder.layer.6.attention.self.query', 'encoder.layer.6.attention.self.value', 'encoder.layer.6.intermediate.dense', 'encoder.layer.6.output.dense', 'encoder.layer.7.attention.output.dense', 'encoder.layer.7.attention.self.key', 'encoder.layer.7.attention.self.query', 'encoder.layer.7.attention.self.value', 'encoder.layer.7.intermediate.dense', 'encoder.layer.7.output.dense', 'encoder.layer.8.attention.output.dense', 'encoder.layer.8.attention.self.key', 'encoder.layer.8.attention.self.query', 'encoder.layer.8.attention.self.value', 'encoder.layer.8.intermediate.dense', 'encoder.layer.8.output.dense', 'encoder.layer.9.attention.output.dense', 'encoder.layer.9.attention.self.key', 'encoder.layer.9.attention.self.query', 'encoder.layer.9.attention.self.value', 'encoder.layer.9.intermediate.dense', 'encoder.layer.9.output.dense']\n"
     ]
    }
   ],
   "source": [
    "# Identify explicit target modules for LoRA adaptation within the BERT model's encoder\n",
    "explicit_target_modules = []\n",
    "for name, module in model.bert.named_modules():\n",
    "    if isinstance(module, nn.Linear):\n",
    "        if 'pooler.dense' not in name:\n",
    "            explicit_target_modules.append(name)\n",
    "\n",
    "# Remove duplicates that might arise if a module is listed multiple times\n",
    "explicit_target_modules = sorted(list(set(explicit_target_modules)))\n",
    "\n",
    "if not explicit_target_modules:\n",
    "    print(\"Warning: No nn.Linear target modules found in model.bert. Falling back to generic list.\")\n",
    "    # Fallback to a generic list if the dynamic search fails (less precise)\n",
    "    explicit_target_modules = [\"query\", \"key\", \"value\", \"dense\"]\n",
    "else:\n",
    "    print(f\"Refined LoRA target modules for BERT (full names within model.bert): {explicit_target_modules}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters after LoRA adaptation:\n",
      "trainable params: 5,339,176 || all params: 114,852,176 || trainable%: 4.6487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:168: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Configure LoRA (Low-Rank Adaptation)\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    target_modules=explicit_target_modules, # Use the refined list of full module names\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "\n",
    "# Apply LoRA to the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "print(\"Trainable parameters after LoRA adaptation:\")\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Enable gradient checkpointing to save memory during training\n",
    "if hasattr(model, \"gradient_checkpointing_enable\"):\n",
    "    model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Trainer with Weighted Loss \n",
    "class WeightedLossTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None): # Added num_items_in_batch to signature\n",
    "        # num_items_in_batch is now an accepted argument from the Trainer call, can be ignored.\n",
    "        # Also, pop it from the inputs dictionary if it's there as a key, to prevent passing to model's forward.\n",
    "        inputs.pop(\"num_items_in_batch\", None)\n",
    "\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        \n",
    "        # Prepare inputs for the model, ensuring only expected keys are passed\n",
    "        # These are the standard arguments for BERT-like models.\n",
    "        model_input_args = {\n",
    "            \"input_ids\": inputs.get(\"input_ids\"),\n",
    "            \"attention_mask\": inputs.get(\"attention_mask\"),\n",
    "        }\n",
    "        # Add token_type_ids if it exists in inputs and is not None (BERT uses it)\n",
    "        if \"token_type_ids\" in inputs and inputs.get(\"token_type_ids\") is not None:\n",
    "            model_input_args[\"token_type_ids\"] = inputs[\"token_type_ids\"]\n",
    "        \n",
    "        # Filter out any keys with None values before passing to model\n",
    "        model_input_args = {k: v for k, v in model_input_args.items() if v is not None}\n",
    "\n",
    "        outputs = model(**model_input_args)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        \n",
    "        # Move class_weights to the same device as logits\n",
    "        weights = self.class_weights.to(logits.device) if self.class_weights is not None else None\n",
    "        loss_fct = CrossEntropyLoss(weight=weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Metrics Computation Function (Multi-class)\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # For multi-class, use 'weighted' or 'macro' average for precision, recall, f1\n",
    "    # 'weighted' accounts for label imbalance.\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average='weighted', zero_division=0\n",
    "    )\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1, # Explicitly name it\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2823731/3201283716.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedLossTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Update training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"bert_multiclass_v1\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=8,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    # eval_steps=100,\n",
    "    save_strategy=\"epoch\",\n",
    "    # save_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    report_to=[\"wandb\"],\n",
    "    remove_unused_columns=True,\n",
    "    label_names=[\"labels\"],\n",
    ")\n",
    "\n",
    "# Create trainer with minimal configuration\n",
    "trainer = WeightedLossTrainer( # Use the custom trainer\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    # callbacks=[early_stop],\n",
    "    class_weights=class_weights # Pass the computed class weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 48:31, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.698274</td>\n",
       "      <td>0.521531</td>\n",
       "      <td>0.432743</td>\n",
       "      <td>0.377232</td>\n",
       "      <td>0.521531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11.939400</td>\n",
       "      <td>1.596963</td>\n",
       "      <td>0.564593</td>\n",
       "      <td>0.494131</td>\n",
       "      <td>0.506601</td>\n",
       "      <td>0.564593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.034500</td>\n",
       "      <td>1.530189</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.515968</td>\n",
       "      <td>0.519949</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.402600</td>\n",
       "      <td>1.503819</td>\n",
       "      <td>0.593301</td>\n",
       "      <td>0.534353</td>\n",
       "      <td>0.518898</td>\n",
       "      <td>0.593301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>9.906800</td>\n",
       "      <td>1.496084</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.526658</td>\n",
       "      <td>0.507992</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>9.452000</td>\n",
       "      <td>1.476042</td>\n",
       "      <td>0.622010</td>\n",
       "      <td>0.571370</td>\n",
       "      <td>0.573222</td>\n",
       "      <td>0.622010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>9.358200</td>\n",
       "      <td>1.457472</td>\n",
       "      <td>0.617225</td>\n",
       "      <td>0.565550</td>\n",
       "      <td>0.560102</td>\n",
       "      <td>0.617225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3336, training_loss=10.239503416797811, metrics={'train_runtime': 2912.7684, 'train_samples_per_second': 9.179, 'train_steps_per_second': 1.145, 'total_flos': 1864531098525696.0, 'train_loss': 10.239503416797811, 'epoch': 7.981448234590066})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating the fine-tuned LoRA model on the TEST set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Set Evaluation Results (LoRA Multi-class) ===\n",
      "  accuracy: 0.6794\n",
      "  f1: 0.6254\n",
      "  precision: 0.5975\n",
      "  recall: 0.6794\n",
      "\n",
      "=== Detailed Classification Report on Test Set (LoRA Multi-class) ===\n",
      "Number of unique labels in test set results: 31\n",
      "Number of target names for report: 31\n",
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                                   Art_Music     0.0000    0.0000    0.0000         1\n",
      "                             Casino_Gambling     0.0000    0.0000    0.0000         2\n",
      "                    Counterfeit Credit-Cards     0.6800    1.0000    0.8095        17\n",
      "                           Counterfeit Money     1.0000    0.5000    0.6667         4\n",
      "Counterfeit Personal-Identification_Passport     1.0000    0.8000    0.8889         5\n",
      "                              Cryptocurrency     0.8689    0.9464    0.9060        56\n",
      "                                Cryptolocker     1.0000    0.9583    0.9787        24\n",
      "                               Drugs_Illegal     0.5758    0.8636    0.6909        22\n",
      "                               Forum_Illegal     0.0000    0.0000    0.0000         3\n",
      "                                 Forum_Legal     0.0000    0.0000    0.0000         7\n",
      "                                     Hacking     0.5000    0.1111    0.1818         9\n",
      "                           Hosting_Directory     0.4000    0.5000    0.4444         4\n",
      "                        Hosting_File-sharing     0.4400    0.7857    0.5641        14\n",
      "                             Hosting_Folders     0.0000    0.0000    0.0000         5\n",
      "                       Hosting_Search-Engine     0.0000    0.0000    0.0000         5\n",
      "                              Hosting_Server     0.9474    0.9677    0.9574        93\n",
      "                            Hosting_Software     0.5682    0.7576    0.6494        33\n",
      "                                 Leaked-Data     0.0000    0.0000    0.0000         2\n",
      "                               Library_Books     0.0000    0.0000    0.0000         4\n",
      "                         Marketplace_Illegal     0.0000    0.0000    0.0000         9\n",
      "                           Marketplace_Legal     0.0000    0.0000    0.0000         3\n",
      "                                    Personal     0.3662    0.6047    0.4561        43\n",
      "                     Porno_Child-pornography     0.0000    0.0000    0.0000         4\n",
      "                   Porno_General-pornography     0.5556    0.7143    0.6250         7\n",
      "                              Services_Legal     0.0000    0.0000    0.0000        17\n",
      "                         Social-Network_Blog     0.1429    0.1000    0.1176        10\n",
      "                         Social-Network_Chat     0.0000    0.0000    0.0000         6\n",
      "                        Social-Network_Email     0.4286    0.7500    0.5455         4\n",
      "                         Social-Network_News     0.0000    0.0000    0.0000         2\n",
      "                               Violence_Hate     0.0000    0.0000    0.0000         1\n",
      "                            Violence_Weapons     1.0000    1.0000    1.0000         2\n",
      "\n",
      "                                    accuracy                         0.6794       418\n",
      "                                   macro avg     0.3378    0.3664    0.3381       418\n",
      "                                weighted avg     0.5975    0.6794    0.6254       418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model on the Test Set \n",
    "print(\"\\nEvaluating the fine-tuned LoRA model on the TEST set...\")\n",
    "test_predictions_output = trainer.predict(tokenized_test_dataset)\n",
    "test_metrics = compute_metrics((test_predictions_output.predictions, test_predictions_output.label_ids))\n",
    "\n",
    "print(\"\\n=== Test Set Evaluation Results (LoRA Multi-class) ===\")\n",
    "for key, value in test_metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n=== Detailed Classification Report on Test Set (LoRA Multi-class) ===\")\n",
    "y_test_preds = np.argmax(test_predictions_output.predictions, axis=-1)\n",
    "y_test_true = test_predictions_output.label_ids\n",
    "\n",
    "# Get unique labels present in the test set predictions and true labels\n",
    "present_labels = np.unique(np.concatenate((y_test_true, y_test_preds)))\n",
    "# Filter target_names to only include names for labels present in the test set\n",
    "# Ensure they are sorted according to present_labels for correct mapping\n",
    "target_names_for_report = [id2label[label_idx] for label_idx in sorted(present_labels)]\n",
    "# The 'labels' parameter in classification_report should be the sorted unique labels that correspond to the order of target_names_for_report.\n",
    "labels_for_report = sorted(present_labels)\n",
    "\n",
    "print(f\"Number of unique labels in test set results: {len(labels_for_report)}\")\n",
    "print(f\"Number of target names for report: {len(target_names_for_report)}\")\n",
    "\n",
    "\n",
    "print(classification_report(y_test_true, y_test_preds, labels=labels_for_report, target_names=target_names_for_report, digits=4, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▁▂▂▂▂▂▂▂▁▁▃▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>eval/f1</td><td>▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▅▆▆▆▇▇▆▇▇█▇██</td></tr><tr><td>eval/loss</td><td>█▇▇▆▆▆▆▆▆█▇▇▆▆▆▆▆▆█████▇▇▇▇▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▅▆▆▆▆▆▆▇▇▇▇██</td></tr><tr><td>eval/recall</td><td>▁▁▂▂▂▂▂▂▂▁▁▃▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▆▇▇▇▇▇▇▇▇████</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█████████████</td></tr><tr><td>eval/samples_per_second</td><td>███████████████████████████▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/steps_per_second</td><td>▅▄▃▄▃▄▄▂▄▅▄██▇▇█▅▅▅▄▆▇▆█▃▄▆▃▃▃▅▂▁▇▅▆▆▆▃▆</td></tr><tr><td>test/accuracy</td><td>▁▁▂█</td></tr><tr><td>test/f1</td><td>▁▁▂█</td></tr><tr><td>test/loss</td><td>▇▇█▁</td></tr><tr><td>test/precision</td><td>▁▁▂█</td></tr><tr><td>test/recall</td><td>▁▁▂█</td></tr><tr><td>test/runtime</td><td>▁▁▁█</td></tr><tr><td>test/samples_per_second</td><td>█▇█▁</td></tr><tr><td>test/steps_per_second</td><td>█▁▇▇</td></tr><tr><td>train/epoch</td><td>▂▃▄▄▅▆██▁▂▄▄▅▆▆███▁▃▄▄▅▆▇▁▁▂▃▄▅▆▁▁▂▄▄▅▅▆</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▂▃▁▁▁▂▃▃▃▃▃▁▁▂▂▂▃▃▃▃▂▄▅▆▆▇█▂▂▄▄▅▆▆██</td></tr><tr><td>train/grad_norm</td><td>▁▁▁▁▂▂▅▃▃▆▄▆▅▃▄█▄▆</td></tr><tr><td>train/learning_rate</td><td>▂▁▂▁▂▁█▇▅▄▃▂▆▅▄▃▂▁</td></tr><tr><td>train/loss</td><td>▁▁▁▁▅▅█▆▅▅▄▄▄▄▄▃▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.61722</td></tr><tr><td>eval/f1</td><td>0.56555</td></tr><tr><td>eval/loss</td><td>1.45747</td></tr><tr><td>eval/precision</td><td>0.5601</td></tr><tr><td>eval/recall</td><td>0.61722</td></tr><tr><td>eval/runtime</td><td>11.5659</td></tr><tr><td>eval/samples_per_second</td><td>36.141</td></tr><tr><td>eval/steps_per_second</td><td>36.141</td></tr><tr><td>test/accuracy</td><td>0.67943</td></tr><tr><td>test/f1</td><td>0.62542</td></tr><tr><td>test/loss</td><td>1.27102</td></tr><tr><td>test/precision</td><td>0.59755</td></tr><tr><td>test/recall</td><td>0.67943</td></tr><tr><td>test/runtime</td><td>11.6858</td></tr><tr><td>test/samples_per_second</td><td>35.77</td></tr><tr><td>test/steps_per_second</td><td>35.77</td></tr><tr><td>total_flos</td><td>1864531098525696.0</td></tr><tr><td>train/epoch</td><td>7.98145</td></tr><tr><td>train/global_step</td><td>3336</td></tr><tr><td>train/grad_norm</td><td>72.30492</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>9.3582</td></tr><tr><td>train_loss</td><td>10.2395</td></tr><tr><td>train_runtime</td><td>2912.7684</td></tr><tr><td>train_samples_per_second</td><td>9.179</td></tr><tr><td>train_steps_per_second</td><td>1.145</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">serene-snowball-3</strong> at: <a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29/runs/c6c4wsy7' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29/runs/c6c4wsy7</a><br> View project at: <a href='https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20BERT%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250523_015656-c6c4wsy7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finish the Weights & Biases run\n",
    "wandb.finish()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert_multiclass_v1/tokenizer_config.json',\n",
       " 'bert_multiclass_v1/special_tokens_map.json',\n",
       " 'bert_multiclass_v1/vocab.txt',\n",
       " 'bert_multiclass_v1/added_tokens.json')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model and tokenizer\n",
    "trainer.save_model(\"bert_multiclass_v1\")\n",
    "tokenizer.save_pretrained(\"bert_multiclass_v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
