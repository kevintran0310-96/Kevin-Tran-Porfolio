{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version improve the matching code from the answer to fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqtra0027\u001b[0m (\u001b[33mailecs-lab-students\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login to Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/Pycharm Project/DUTA10K/wandb/run-20250520_010919-5kq4r01q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29_ver2/runs/5kq4r01q?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">vocal-star-21</a></strong> to <a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29_ver2?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29_ver2?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29_ver2?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29_ver2/runs/5kq4r01q?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29_ver2/runs/5kq4r01q?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a new Weights & Biases run for experiment tracking\n",
    "run = wandb.init(\n",
    "    project='Using Gemma3_4b to classify illicit content on online marketplace (multiclass classification)_ver2', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from transformers.models.gemma3.modeling_gemma3 import Gemma3ForCausalLM\n",
    "from peft import (\n",
    "    prepare_model_for_kbit_training,\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    PeftModelForSequenceClassification,\n",
    "    PeftConfig,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Set TOKENIZERS_PARALLELISM to avoid warnings when forking processes\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# Set PYTORCH_CUDA_ALLOC_CONF for potentially better memory management\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "graphic_card = '0' # choose which graphic card\n",
    "gpu_device   = 'cuda:0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = graphic_card\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]    = \"PCI_BUS_ID\"\n",
    "device       = torch.device(f\"cuda:{graphic_card}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.cuda.set_device(0)  \n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & inspect data\n",
    "file_path = \"DUTA10K_final.jsonl\"\n",
    "df = pd.read_json(file_path, lines=True)                                \n",
    "df.dropna(subset=['category', 'text'], inplace=True)\n",
    "df = df[df['text'].str.strip() != ''] \n",
    "df.reset_index(drop=True, inplace=True) \n",
    "\n",
    "# Map categories to integer labels\n",
    "categories = sorted(df[\"category\"].unique())\n",
    "label2id   = {cat: idx for idx, cat in enumerate(categories)}\n",
    "id2label   = {idx: cat for cat, idx in label2id.items()}\n",
    "df[\"category_id\"] = df[\"category\"].map(label2id)\n",
    "\n",
    "# Build a HuggingFace DatasetDict\n",
    "ds = Dataset.from_pandas(\n",
    "    df[[\"text\", \"category_id\"]]\n",
    "      .rename(columns={\"category_id\": \"label\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/10/10 split\n",
    "split1 = ds.train_test_split(test_size=0.2, seed=42)\n",
    "split2 = split1[\"test\"].train_test_split(test_size=0.5, seed=42)\n",
    "ds = DatasetDict({\n",
    "    \"train\": split1[\"train\"],\n",
    "    \"eval\":  split2[\"train\"],\n",
    "    \"test\":  split2[\"test\"],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deee65f2a3e443b192a8e999ed14290a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3342 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f21ce1403c47d295d41450a7c4402e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8568c505dde4b608a5fa90f88e09bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/418 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "base_model = \"google/gemma-3-4b-it\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "MAX_LEN = 512\n",
    "\n",
    "# Preprocessing function to tokenize text and add labels\n",
    "def preprocess(examples):\n",
    "    tokens = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    tokens[\"labels\"] = examples[\"label\"]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to the datasets and remove the original 'text' column\n",
    "tokenized = ds.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8e30417a0548d1983fe161b22195c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Gemma-3 as a CausalLM & swap in a classifier head\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "model = Gemma3ForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Replace the language modeling head (lm_head) with a new linear layer for classification\n",
    "model.lm_head = torch.nn.Linear(\n",
    "    model.config.hidden_size,\n",
    "    len(categories),\n",
    "    bias=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for k-bit tuning & inject LoRA\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=32, # LoRA rank\n",
    "    lora_alpha=32, # LoRA scaling factor\n",
    "    target_modules=[\"gate_proj\",\"down_proj\",\"v_proj\",\"k_proj\",\"q_proj\",\"o_proj\",\"up_proj\"], # Modules to apply LoRA to\n",
    "    lora_dropout=0.1, # Dropout probability for LoRA layers\n",
    "    bias=\"none\", # Do not apply bias to LoRA weights\n",
    "    task_type=\"SEQ_CLS\", # Sequence Classification task\n",
    ")\n",
    "\n",
    "# Get the PEFT (Parameter-Efficient Fine-Tuning) model\n",
    "model = get_peft_model(model, lora_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:168: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Wrap in a SequenceClassification PEFT model\n",
    "class GEMMA3SeqClassifier(PeftModelForSequenceClassification):\n",
    "    def __init__(self, peft_config: PeftConfig, base_model: torch.nn.Module):\n",
    "        super().__init__(base_model, peft_config)\n",
    "        self.num_labels = len(categories)\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, labels=None, **kwargs):\n",
    "        outputs = self.base_model(input_ids=input_ids, attention_mask=attention_mask, **kwargs)\n",
    "        # take the last non-pad token‚Äôs logits\n",
    "        seq_len = attention_mask.sum(dim=1) - 1\n",
    "        batch_ix = torch.arange(len(seq_len), device=seq_len.device)\n",
    "        logits = outputs.logits[batch_ix, seq_len, :]\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = torch.nn.CrossEntropyLoss()(logits, labels)\n",
    "        return SequenceClassifierOutput(loss=loss, logits=logits)\n",
    "\n",
    "# Instantiate the custom wrapped model\n",
    "model = GEMMA3SeqClassifier(lora_cfg, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics & Trainer setup\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    labs  = p.label_ids\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(labs, preds, average=\"weighted\", zero_division=0)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labs, preds),\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2636220/2383830507.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `GEMMA3SeqClassifier`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "# Training arguments configuration\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gemma3_multiclass_ver2\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=8,\n",
    "    fp16=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"wandb\",\n",
    ")\n",
    "\n",
    "# Initialize the Hugging Face Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"eval\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "It is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `sdpa`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 4:40:48, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.792346</td>\n",
       "      <td>0.449761</td>\n",
       "      <td>0.451158</td>\n",
       "      <td>0.449761</td>\n",
       "      <td>0.387327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.336200</td>\n",
       "      <td>1.185785</td>\n",
       "      <td>0.696172</td>\n",
       "      <td>0.705153</td>\n",
       "      <td>0.696172</td>\n",
       "      <td>0.675173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.352200</td>\n",
       "      <td>1.186292</td>\n",
       "      <td>0.715311</td>\n",
       "      <td>0.703673</td>\n",
       "      <td>0.715311</td>\n",
       "      <td>0.701803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.217700</td>\n",
       "      <td>1.898075</td>\n",
       "      <td>0.708134</td>\n",
       "      <td>0.700239</td>\n",
       "      <td>0.708134</td>\n",
       "      <td>0.696537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.678100</td>\n",
       "      <td>2.175120</td>\n",
       "      <td>0.720096</td>\n",
       "      <td>0.723718</td>\n",
       "      <td>0.720096</td>\n",
       "      <td>0.710796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.486200</td>\n",
       "      <td>2.176732</td>\n",
       "      <td>0.720096</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.720096</td>\n",
       "      <td>0.710441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.554100</td>\n",
       "      <td>2.117707</td>\n",
       "      <td>0.732057</td>\n",
       "      <td>0.730424</td>\n",
       "      <td>0.732057</td>\n",
       "      <td>0.723018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3336, training_loss=7.34927185204961, metrics={'train_runtime': 16853.9598, 'train_samples_per_second': 1.586, 'train_steps_per_second': 0.198, 'total_flos': 2.6784702607220736e+17, 'train_loss': 7.34927185204961, 'epoch': 7.981448234590066})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the model on the test set and print classification report and confusion matrix\n",
    "def evaluate_on_test(trainer, test_dataset, id2label):\n",
    "    # Get predictions\n",
    "    preds_output = trainer.predict(test_dataset)\n",
    "    y_true = preds_output.label_ids\n",
    "    y_pred = np.argmax(preds_output.predictions, axis=-1)\n",
    "\n",
    "    # Which labels actually appear in the test set?\n",
    "    present_labels = sorted(set(y_true.tolist()))\n",
    "    present_names  = [id2label[i] for i in present_labels]\n",
    "\n",
    "    # Print report for only those classes\n",
    "    print(\"=== Classification Report ===\")\n",
    "    print(classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=present_labels,\n",
    "        target_names=present_names,\n",
    "        zero_division=0,\n",
    "        digits=4\n",
    "    ))\n",
    "\n",
    "    # Confusion matrix (same subset of labels)\n",
    "    print(\"=== Confusion Matrix ===\")\n",
    "    print(confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=present_labels\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                                   Art_Music     1.0000    0.5000    0.6667         2\n",
      "                             Casino_Gambling     1.0000    1.0000    1.0000         2\n",
      "                    Counterfeit Credit-Cards     0.8800    0.9565    0.9167        23\n",
      "                           Counterfeit Money     1.0000    0.8571    0.9231         7\n",
      "Counterfeit Personal-Identification_Passport     1.0000    0.5000    0.6667         4\n",
      "                              Cryptocurrency     0.9149    0.8269    0.8687        52\n",
      "                                Cryptolocker     0.8889    0.6667    0.7619        12\n",
      "                               Drugs_Illegal     0.7692    0.8696    0.8163        23\n",
      "                               Forum_Illegal     0.6667    0.4000    0.5000         5\n",
      "                                 Forum_Legal     0.5000    0.3750    0.4286         8\n",
      "                                       Fraud     0.0000    0.0000    0.0000         1\n",
      "                                     Hacking     0.7500    0.5000    0.6000         6\n",
      "                           Hosting_Directory     0.8000    0.8000    0.8000         5\n",
      "                        Hosting_File-sharing     0.5714    0.4444    0.5000         9\n",
      "                             Hosting_Folders     0.5000    0.5000    0.5000         8\n",
      "                       Hosting_Search-Engine     0.0000    0.0000    0.0000         6\n",
      "                              Hosting_Server     0.6692    0.9667    0.7909        90\n",
      "                            Hosting_Software     0.6207    0.7200    0.6667        25\n",
      "                           Human-Trafficking     0.0000    0.0000    0.0000         1\n",
      "                                 Leaked-Data     0.5000    0.5000    0.5000         2\n",
      "                         Marketplace_Illegal     0.5000    0.1000    0.1667        10\n",
      "                           Marketplace_Legal     0.7500    0.7500    0.7500         8\n",
      "                                    Personal     0.3714    0.3714    0.3714        35\n",
      "                                    Politics     1.0000    0.5000    0.6667         2\n",
      "                     Porno_Child-pornography     0.8000    0.6667    0.7273         6\n",
      "                   Porno_General-pornography     0.8889    0.7273    0.8000        11\n",
      "                                    Religion     0.0000    0.0000    0.0000         1\n",
      "                              Services_Legal     0.4286    0.1875    0.2609        16\n",
      "                         Social-Network_Blog     0.5455    0.3750    0.4444        16\n",
      "                         Social-Network_Chat     1.0000    0.4444    0.6154         9\n",
      "                        Social-Network_Email     0.7500    0.7500    0.7500         4\n",
      "                         Social-Network_News     0.0000    0.0000    0.0000         2\n",
      "                               Violence_Hate     0.0000    0.0000    0.0000         1\n",
      "                             Violence_Hitman     1.0000    0.5000    0.6667         2\n",
      "                            Violence_Weapons     0.6667    1.0000    0.8000         4\n",
      "\n",
      "                                   micro avg     0.6877    0.6794    0.6835       418\n",
      "                                   macro avg     0.6209    0.5073    0.5407       418\n",
      "                                weighted avg     0.6836    0.6794    0.6628       418\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[ 1  0  0 ...  0  0  0]\n",
      " [ 0  2  0 ...  0  0  0]\n",
      " [ 0  0 22 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  1  1]\n",
      " [ 0  0  0 ...  0  0  4]]\n"
     ]
    }
   ],
   "source": [
    "# Perform evaluation on the test dataset\n",
    "evaluate_on_test(trainer, tokenized[\"test\"], id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>‚ñÅ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/f1</td><td>‚ñÅ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/loss</td><td>‚ñÖ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñà‚ñá‚ñà</td></tr><tr><td>eval/precision</td><td>‚ñÅ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/recall</td><td>‚ñÅ‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñà‚ñÑ‚ñÑ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñÜ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÖ‚ñÖ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñÜ‚ñà‚ñá‚ñÅ‚ñÅ‚ñÖ‚ñÖ</td></tr><tr><td>test/accuracy</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>test/f1</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>test/loss</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>test/precision</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>test/recall</td><td>‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>test/runtime</td><td>‚ñÉ‚ñÅ‚ñà</td></tr><tr><td>test/samples_per_second</td><td>‚ñÜ‚ñà‚ñÅ</td></tr><tr><td>test/steps_per_second</td><td>‚ñÜ‚ñà‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñà‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñà‚ñá‚ñÖ‚ñÑ‚ñÇ‚ñÅ</td></tr><tr><td>train/loss</td><td>‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.73206</td></tr><tr><td>eval/f1</td><td>0.72302</td></tr><tr><td>eval/loss</td><td>2.11771</td></tr><tr><td>eval/precision</td><td>0.73042</td></tr><tr><td>eval/recall</td><td>0.73206</td></tr><tr><td>eval/runtime</td><td>74.022</td></tr><tr><td>eval/samples_per_second</td><td>5.647</td></tr><tr><td>eval/steps_per_second</td><td>0.716</td></tr><tr><td>test/accuracy</td><td>0.67943</td></tr><tr><td>test/f1</td><td>0.66276</td></tr><tr><td>test/loss</td><td>2.55644</td></tr><tr><td>test/precision</td><td>0.68356</td></tr><tr><td>test/recall</td><td>0.67943</td></tr><tr><td>test/runtime</td><td>73.1644</td></tr><tr><td>test/samples_per_second</td><td>5.713</td></tr><tr><td>test/steps_per_second</td><td>0.724</td></tr><tr><td>total_flos</td><td>2.6784702607220736e+17</td></tr><tr><td>train/epoch</td><td>7.98145</td></tr><tr><td>train/global_step</td><td>3336</td></tr><tr><td>train/grad_norm</td><td>1.48279</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>3.5541</td></tr><tr><td>train_loss</td><td>7.34927</td></tr><tr><td>train_runtime</td><td>16853.9598</td></tr><tr><td>train_samples_per_second</td><td>1.586</td></tr><tr><td>train_steps_per_second</td><td>0.198</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vocal-star-21</strong> at: <a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29_ver2/runs/5kq4r01q?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29_ver2/runs/5kq4r01q?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f</a><br> View project at: <a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29_ver2?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28multiclass%20classification%29_ver2?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_010919-5kq4r01q/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finish the Weights & Biases run\n",
    "wandb.finish()\n",
    "model.config.use_cache = True # Set use_cache to True for optimized inference after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gemma3_multiclass_ver2/tokenizer_config.json',\n",
       " 'gemma3_multiclass_ver2/special_tokens_map.json',\n",
       " 'gemma3_multiclass_ver2/chat_template.jinja',\n",
       " 'gemma3_multiclass_ver2/tokenizer.model',\n",
       " 'gemma3_multiclass_ver2/added_tokens.json',\n",
       " 'gemma3_multiclass_ver2/tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model and tokenizer\n",
    "trainer.save_model(\"gemma3_multiclass_ver2\")\n",
    "tokenizer.save_pretrained(\"gemma3_multiclass_ver2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from peft import PeftModel\n",
    "\n",
    "# üîê Login to HuggingFace\n",
    "from getpass import getpass\n",
    "hf_token = getpass(\"Enter your HuggingFace token: \")\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Base and fine-tuned model paths\n",
    "base_model = \"google/gemma-3-4b-it\"\n",
    "fine_tuned_model = \"gemma3_multiclass_ver2\" \n",
    "\n",
    "# üîÅ Reload tokenizer and base model\n",
    "print(\"üîÑ Loading base tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "base_model_reload = GemmaForSequenceClassification.from_pretrained(\n",
    "    base_model,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìé Merge adapter\n",
    "print(\"üîó Merging LoRA adapter with base model...\")\n",
    "model = PeftModel.from_pretrained(base_model_reload, fine_tuned_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# üíæ Save locally and push to HF Hub\n",
    "model_dir = \"gemma3_multiclass_ver2\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# ‚òÅÔ∏è Push to Hugging Face\n",
    "model.push_to_hub(model_dir, use_temp_dir=False)\n",
    "tokenizer.push_to_hub(model_dir, use_temp_dir=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
