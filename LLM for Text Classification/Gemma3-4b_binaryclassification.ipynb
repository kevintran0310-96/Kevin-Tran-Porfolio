{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version improve the matching code from the answer to fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mqtra0027\u001b[0m (\u001b[33mailecs-lab-students\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login to Weights & Biases for experiment tracking\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/Pycharm Project/DUTA10K/wandb/run-20250515_225547-aw5eoh3v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28binary%20classification%29_ver2/runs/aw5eoh3v?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">noble-flower-3</a></strong> to <a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28binary%20classification%29_ver2?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28binary%20classification%29_ver2?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28binary%20classification%29_ver2?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28binary%20classification%29_ver2/runs/aw5eoh3v?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28binary%20classification%29_ver2/runs/aw5eoh3v?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize a new Weights & Biases run for experiment tracking\n",
    "run = wandb.init(\n",
    "    project='Using Gemma3_4b to classify illicit content on online marketplace (binary classification)_ver2', \n",
    "    job_type=\"training\", \n",
    "    anonymous=\"allow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import bitsandbytes as bnb\n",
    "import evaluate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset, DatasetDict\n",
    "from peft import LoraConfig, PeftConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import (GemmaForSequenceClassification, \n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          DataCollatorWithPadding)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                            precision_score, \n",
    "                            recall_score, \n",
    "                            f1_score, \n",
    "                            classification_report, \n",
    "                            confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Unique categories found:\n",
      "- Art_Music\n",
      "- Casino_Gambling\n",
      "- Counterfeit Credit-Cards\n",
      "- Counterfeit Money\n",
      "- Counterfeit Personal-Identification_Driving-Licence\n",
      "- Counterfeit Personal-Identification_ID\n",
      "- Counterfeit Personal-Identification_Passport\n",
      "- Cryptocurrency\n",
      "- Cryptolocker\n",
      "- Drugs_Illegal\n",
      "- Drugs_Legal\n",
      "- Forum_Illegal\n",
      "- Forum_Legal\n",
      "- Fraud\n",
      "- Hacking\n",
      "- Hosting_Directory\n",
      "- Hosting_File-sharing\n",
      "- Hosting_Folders\n",
      "- Hosting_Search-Engine\n",
      "- Hosting_Server\n",
      "- Hosting_Software\n",
      "- Human-Trafficking\n",
      "- Leaked-Data\n",
      "- Library_Books\n",
      "- Marketplace_Illegal\n",
      "- Marketplace_Legal\n",
      "- Personal\n",
      "- Politics\n",
      "- Porno_Child-pornography\n",
      "- Porno_General-pornography\n",
      "- Religion\n",
      "- Services_Illegal\n",
      "- Services_Legal\n",
      "- Social-Network_Blog\n",
      "- Social-Network_Chat\n",
      "- Social-Network_Email\n",
      "- Social-Network_News\n",
      "- Violence_Hate\n",
      "- Violence_Hitman\n",
      "- Violence_Weapons\n",
      "\n",
      "📊 Category distribution:\n",
      "category\n",
      "Hosting_Server                                         760\n",
      "Cryptocurrency                                         577\n",
      "Personal                                               460\n",
      "Hosting_Software                                       248\n",
      "Drugs_Illegal                                          225\n",
      "Counterfeit Credit-Cards                               214\n",
      "Cryptolocker                                           169\n",
      "Services_Legal                                         159\n",
      "Hosting_File-sharing                                   138\n",
      "Social-Network_Blog                                    122\n",
      "Hacking                                                103\n",
      "Marketplace_Legal                                       88\n",
      "Forum_Legal                                             87\n",
      "Hosting_Directory                                       79\n",
      "Porno_General-pornography                               74\n",
      "Marketplace_Illegal                                     72\n",
      "Hosting_Folders                                         67\n",
      "Social-Network_Email                                    57\n",
      "Social-Network_Chat                                     55\n",
      "Porno_Child-pornography                                 55\n",
      "Hosting_Search-Engine                                   48\n",
      "Counterfeit Money                                       45\n",
      "Forum_Illegal                                           35\n",
      "Social-Network_News                                     33\n",
      "Library_Books                                           32\n",
      "Violence_Weapons                                        29\n",
      "Counterfeit Personal-Identification_Passport            28\n",
      "Casino_Gambling                                         26\n",
      "Violence_Hitman                                         15\n",
      "Leaked-Data                                             15\n",
      "Art_Music                                               12\n",
      "Violence_Hate                                           12\n",
      "Politics                                                11\n",
      "Religion                                                 8\n",
      "Counterfeit Personal-Identification_ID                   7\n",
      "Drugs_Legal                                              4\n",
      "Services_Illegal                                         3\n",
      "Human-Trafficking                                        3\n",
      "Fraud                                                    2\n",
      "Counterfeit Personal-Identification_Driving-Licence      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load JSONL file\n",
    "file_path = \"DUTA10K_final.jsonl\"\n",
    "df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "# List all unique categories\n",
    "unique_categories = df[\"category\"].dropna().unique()\n",
    "\n",
    "# Print the categories\n",
    "print(\"✅ Unique categories found:\")\n",
    "for cat in sorted(unique_categories):\n",
    "    print(\"-\", cat)\n",
    "\n",
    "# Get category counts\n",
    "print(\"\\n📊 Category distribution:\")\n",
    "print(df[\"category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train=3342 | Eval=417 | Test=419\n"
     ]
    }
   ],
   "source": [
    "# Define split sizes and split the DataFrame into training, evaluation, and test sets\n",
    "n = len(df)\n",
    "train_end = int(0.8 * n)\n",
    "eval_end  = train_end + int(0.1 * n)\n",
    "\n",
    "df_train = df.iloc[:train_end]\n",
    "df_eval  = df.iloc[train_end:eval_end]\n",
    "df_test  = df.iloc[eval_end:]\n",
    "\n",
    "print(f\"Train={len(df_train)} | Eval={len(df_eval)} | Test={len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DatasetDict from the pandas DataFrames\n",
    "ds = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(df_train),\n",
    "    \"eval\":  Dataset.from_pandas(df_eval),\n",
    "    \"test\":  Dataset.from_pandas(df_test),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc6ad207a43495f8c37f1997cd59e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3342 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b157350f248645a18c362f1b3563cb59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/417 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c736ddd8324fddab12243b2be92941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/419 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the base model tokenizer\n",
    "base_model_name = \"google/gemma-3-4b-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, trust_remote_code=True)\n",
    "\n",
    "MAX_LEN = 10000  # or 1,024 if you have the headroom\n",
    "\n",
    "# Preprocess function to tokenize the text data\n",
    "def preprocess(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        padding=\"max_length\"   # pad shorter examples up to exactly MAX_LEN\n",
    "    )\n",
    "\n",
    "# Apply preprocessing to the datasets\n",
    "tokenized = ds.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data Collator\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics fuction\n",
    "metric = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type gemma3 to instantiate a model of type gemma. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8613033a5b460c915a05d186ea5cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GemmaForSequenceClassification were not initialized from the model checkpoint at google/gemma-3-4b-it and are newly initialized: ['model.embed_tokens.weight', 'model.layers.0.input_layernorm.weight', 'model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.post_attention_layernorm.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.input_layernorm.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.post_attention_layernorm.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.input_layernorm.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.post_attention_layernorm.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.input_layernorm.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.post_attention_layernorm.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.input_layernorm.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.post_attention_layernorm.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.input_layernorm.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.post_attention_layernorm.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.input_layernorm.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.post_attention_layernorm.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.input_layernorm.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.post_attention_layernorm.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.input_layernorm.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.post_attention_layernorm.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.input_layernorm.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.post_attention_layernorm.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.input_layernorm.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.post_attention_layernorm.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.input_layernorm.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.post_attention_layernorm.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.input_layernorm.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.post_attention_layernorm.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.input_layernorm.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.post_attention_layernorm.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.input_layernorm.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.post_attention_layernorm.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.input_layernorm.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.post_attention_layernorm.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.input_layernorm.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.post_attention_layernorm.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.input_layernorm.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.post_attention_layernorm.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.input_layernorm.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.post_attention_layernorm.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.input_layernorm.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.post_attention_layernorm.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.input_layernorm.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.post_attention_layernorm.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.3.input_layernorm.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.post_attention_layernorm.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.4.input_layernorm.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.post_attention_layernorm.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.input_layernorm.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.post_attention_layernorm.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.input_layernorm.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.post_attention_layernorm.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.input_layernorm.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.post_attention_layernorm.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.input_layernorm.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.post_attention_layernorm.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.input_layernorm.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.post_attention_layernorm.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.norm.weight', 'score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load GEMMA‑3 for sequence classification\n",
    "model = GemmaForSequenceClassification.from_pretrained(\n",
    "    base_model_name,\n",
    "    num_labels=2,\n",
    "    id2label={0:\"non‑illicit\", 1:\"illicit\"}, # Mapping from ID to label string\n",
    "    label2id={\"non‑illicit\":0, \"illicit\":1}, # Mapping from label string to ID\n",
    "    torch_dtype=torch.float16, # Use float16 for reduced memory usage\n",
    "    device_map=\"auto\", # Automatically maps model to available devices\n",
    "    trust_remote_code=True, # Allows loading custom code from the model's repository\n",
    ")\n",
    "\n",
    "# Prepare the model for k-bit training (LoRA compatible)\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.gradient_checkpointing_enable() # Enable gradient checkpointing to save memory during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA will target: ['embed_tokens', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj', 'score']\n"
     ]
    }
   ],
   "source": [
    "from transformers.pytorch_utils import Conv1D\n",
    "\n",
    "# Define supported module types for LoRA adaptation\n",
    "SUPPORTED = (nn.Linear, nn.Embedding, nn.Conv1d, nn.Conv2d, nn.Conv3d, Conv1D, nn.MultiheadAttention) # Expanded list from original\n",
    "\n",
    "target_modules = [\n",
    "    name.split(\".\")[-1]\n",
    "    for name, module in model.named_modules()\n",
    "    if isinstance(module, SUPPORTED)\n",
    "]\n",
    "print(\"LoRA will target:\", target_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:529: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['model.embed_tokens'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_2306959/2588455016.py:30: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 216,602,624 || all params: 8,754,289,664 || trainable%: 2.4742\n"
     ]
    }
   ],
   "source": [
    "# LoRA adapter configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=64, # LoRA rank\n",
    "    lora_alpha=32, # LoRA scaling factor\n",
    "    target_modules=target_modules, # Modules to apply LoRA to\n",
    "    lora_dropout=0.1, # Dropout probability for LoRA layers\n",
    "    bias=\"none\", # Do not apply bias to LoRA weights\n",
    "    task_type=\"SEQ_CLS\", # Sequence Classification task\n",
    ")\n",
    "\n",
    "# Get the PEFT (Parameter-Efficient Fine-Tuning) model\n",
    "model = get_peft_model(model, lora_config) \n",
    "model.gradient_checkpointing_enable() # Re-enable gradient checkpointing after wrapping with PEFT model\n",
    "model.print_trainable_parameters() # Print the number of trainable parameters\n",
    "\n",
    "# Training arguments configuration\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"gemma_4b_binary_ver2\", # Output directory for checkpoints and logs\n",
    "    per_device_train_batch_size=1, # Batch size per GPU for training\n",
    "    per_device_eval_batch_size=1, # Batch size per GPU for evaluation\n",
    "    gradient_accumulation_steps=8, # Number of updates steps to accumulate before performing a backward/update pass\n",
    "    learning_rate=2e-5, # Initial learning rate for AdamW optimizer\n",
    "    num_train_epochs=8, # Total number of training epochs\n",
    "    fp16=True, # Enable mixed precision training\n",
    "    eval_strategy=\"epoch\", # Evaluation is done at the end of each epoch\n",
    "    save_strategy=\"epoch\", # Model is saved at the end of each epoch\n",
    "    load_best_model_at_end=True, # Load the best model at the end of training\n",
    "    metric_for_best_model=\"accuracy\", # Metric to use to compare models\n",
    "    report_to=[\"wandb\"], # Report metrics to Weights & Biases\n",
    ")\n",
    "\n",
    "# Initialize the Hugging Face Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"eval\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 66:29:12, Epoch 7/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.822356</td>\n",
       "      <td>0.729017</td>\n",
       "      <td>0.331361</td>\n",
       "      <td>0.294737</td>\n",
       "      <td>0.378378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.785800</td>\n",
       "      <td>0.764468</td>\n",
       "      <td>0.788969</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.143200</td>\n",
       "      <td>0.876286</td>\n",
       "      <td>0.786571</td>\n",
       "      <td>0.350365</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>1.222065</td>\n",
       "      <td>0.810552</td>\n",
       "      <td>0.347107</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.283784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.317229</td>\n",
       "      <td>0.815348</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>0.297297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.326602</td>\n",
       "      <td>0.810552</td>\n",
       "      <td>0.347107</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.283784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.327025</td>\n",
       "      <td>0.810552</td>\n",
       "      <td>0.347107</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.283784</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3336, training_loss=0.1470525722986431, metrics={'train_runtime': 239428.8868, 'train_samples_per_second': 0.112, 'train_steps_per_second': 0.014, 'total_flos': 1.275207811977216e+19, 'train_loss': 0.1470525722986431, 'epoch': 7.981448234590066})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/peft/utils/save_and_load.py:221: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
      "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('gemma_4b_binary_ver2/tokenizer_config.json',\n",
       " 'gemma_4b_binary_ver2/special_tokens_map.json',\n",
       " 'gemma_4b_binary_ver2/chat_template.jinja',\n",
       " 'gemma_4b_binary_ver2/tokenizer.model',\n",
       " 'gemma_4b_binary_ver2/added_tokens.json',\n",
       " 'gemma_4b_binary_ver2/tokenizer.json')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save trained model and tokenizer\n",
    "trainer.save_model(\"gemma_4b_binary_ver2\")\n",
    "tokenizer.save_pretrained(\"gemma_4b_binary_ver2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GemmaForSequenceClassification(\n",
       "      (model): GemmaModel(\n",
       "        (embed_tokens): lora.Embedding(\n",
       "          (base_layer): Embedding(256000, 3072, padding_idx=0)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (lora_A): ModuleDict()\n",
       "          (lora_B): ModuleDict()\n",
       "          (lora_embedding_A): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 64x256000 (cuda:0)])\n",
       "          (lora_embedding_B): ParameterDict(  (default): Parameter containing: [torch.cuda.FloatTensor of size 3072x64 (cuda:0)])\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0-27): 28 x GemmaDecoderLayer(\n",
       "            (self_attn): GemmaAttention(\n",
       "              (q_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (o_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=4096, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "            )\n",
       "            (mlp): GemmaMLP(\n",
       "              (gate_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=24576, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=24576, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (up_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=3072, out_features=24576, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=3072, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=24576, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (down_proj): lora.Linear(\n",
       "                (base_layer): Linear(in_features=24576, out_features=3072, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=24576, out_features=64, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=64, out_features=3072, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (act_fn): PytorchGELUTanh()\n",
       "            )\n",
       "            (input_layernorm): GemmaRMSNorm((3072,), eps=1e-06)\n",
       "            (post_attention_layernorm): GemmaRMSNorm((3072,), eps=1e-06)\n",
       "          )\n",
       "        )\n",
       "        (norm): GemmaRMSNorm((3072,), eps=1e-06)\n",
       "        (rotary_emb): GemmaRotaryEmbedding()\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=3072, out_features=2, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=3072, out_features=2, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure model & tokenizer are on the right device\n",
    "device = next(model.parameters()).device\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions on a single text input\n",
    "def predict(text: str):\n",
    "    # tokenize + move to device\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\", # Return PyTorch tensors\n",
    "        truncation=True, # Truncate if longer than max_length\n",
    "        max_length=512, # Max length for inference\n",
    "        padding=\"max_length\" # Pad to max_length\n",
    "    ).to(device)\n",
    "    \n",
    "    # Perform forward pass without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits  # Get raw logits from the model\n",
    "        \n",
    "    # Apply softmax to get probabilities and convert to numpy array\n",
    "    probs = torch.softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "    \n",
    "    # Get the index of the highest probability\n",
    "    idx   = int(np.argmax(probs))\n",
    "    return {\n",
    "        \"label\":    id2label[idx], # Predicted label string\n",
    "        \"score\":    float(probs[idx]), # Score of the predicted label\n",
    "        \"all_probs\": { id2label[i]: float(probs[i]) for i in range(len(probs)) }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions on the test set using the trainer\n",
    "preds_output = trainer.predict(tokenized[\"test\"])\n",
    "y_true = preds_output.label_ids\n",
    "y_pred = np.argmax(preds_output.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute & print metrics\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "rec  = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1   = f1_score(y_true, y_pred, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8258\n",
      "Test Precision: 0.5873\n",
      "Test Recall:    0.4405\n",
      "Test F1:        0.5034\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " non‑illicit       0.87      0.92      0.89       335\n",
      "     illicit       0.59      0.44      0.50        84\n",
      "\n",
      "    accuracy                           0.83       419\n",
      "   macro avg       0.73      0.68      0.70       419\n",
      "weighted avg       0.81      0.83      0.82       419\n",
      "\n",
      "Confusion Matrix:\n",
      "[[309  26]\n",
      " [ 47  37]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy:  {acc:.4f}\")\n",
    "print(f\"Test Precision: {prec:.4f}\")\n",
    "print(f\"Test Recall:    {rec:.4f}\")\n",
    "print(f\"Test F1:        {f1:.4f}\")\n",
    "\n",
    "# Full classification report + confusion matrix\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"non‑illicit\",\"illicit\"], zero_division=0))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▆█████</td></tr><tr><td>eval/f1</td><td>▁█▃▂▄▂▂▂</td></tr><tr><td>eval/loss</td><td>▂▁▂▇████</td></tr><tr><td>eval/precision</td><td>▁▅▄▇█▇▇▇</td></tr><tr><td>eval/recall</td><td>▆█▃▁▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▁▄▆█▃▂▂▂</td></tr><tr><td>eval/samples_per_second</td><td>██▁▁████</td></tr><tr><td>eval/steps_per_second</td><td>██▁▁████</td></tr><tr><td>test/accuracy</td><td>▁</td></tr><tr><td>test/f1</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision</td><td>▁</td></tr><tr><td>test/recall</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▄▄▅▅▆▆▇▇███</td></tr><tr><td>train/grad_norm</td><td>█▆▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>█▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.81055</td></tr><tr><td>eval/f1</td><td>0.34711</td></tr><tr><td>eval/loss</td><td>1.32702</td></tr><tr><td>eval/precision</td><td>0.44681</td></tr><tr><td>eval/recall</td><td>0.28378</td></tr><tr><td>eval/runtime</td><td>784.4313</td></tr><tr><td>eval/samples_per_second</td><td>0.532</td></tr><tr><td>eval/steps_per_second</td><td>0.532</td></tr><tr><td>test/accuracy</td><td>0.82578</td></tr><tr><td>test/f1</td><td>0.5034</td></tr><tr><td>test/loss</td><td>1.21163</td></tr><tr><td>test/precision</td><td>0.5873</td></tr><tr><td>test/recall</td><td>0.44048</td></tr><tr><td>test/runtime</td><td>789.4286</td></tr><tr><td>test/samples_per_second</td><td>0.531</td></tr><tr><td>test/steps_per_second</td><td>0.531</td></tr><tr><td>total_flos</td><td>1.275207811977216e+19</td></tr><tr><td>train/epoch</td><td>7.98145</td></tr><tr><td>train/global_step</td><td>3336</td></tr><tr><td>train/grad_norm</td><td>0.00258</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0</td></tr><tr><td>train_loss</td><td>0.14705</td></tr><tr><td>train_runtime</td><td>239428.8868</td></tr><tr><td>train_samples_per_second</td><td>0.112</td></tr><tr><td>train_steps_per_second</td><td>0.014</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">noble-flower-3</strong> at: <a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28binary%20classification%29_ver2/runs/aw5eoh3v?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28binary%20classification%29_ver2/runs/aw5eoh3v?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f</a><br> View project at: <a href='https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28binary%20classification%29_ver2?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f' target=\"_blank\">https://wandb.ai/ailecs-lab-students/Using%20Gemma3_4b%20to%20classify%20illicit%20content%20on%20online%20marketplace%20%28binary%20classification%29_ver2?apiKey=7c62613817d0b4287c0beb0cfdd236bbb509d82f</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250515_225547-aw5eoh3v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finish the Weights & Biases run\n",
    "wandb.finish()\n",
    "model.config.use_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 🔐 Login to HuggingFace\n",
    "from getpass import getpass\n",
    "hf_token = getpass(\"Enter your HuggingFace token: \")\n",
    "login(token=hf_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧠 Base and fine-tuned model paths\n",
    "base_model = \"gemma_4b_binary_ver2\"  # You used this in your training code\n",
    "fine_tuned_model = \"gemma_4b_binary_ver2\"  # Your output dir from training\n",
    "\n",
    "# 🔁 Reload tokenizer and base model\n",
    "print(\"🔄 Loading base tokenizer and model...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "base_model_reload = GemmaForSequenceClassification.from_pretrained(\n",
    "    base_model,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📎 Merge adapter\n",
    "print(\"🔗 Merging LoRA adapter with base model...\")\n",
    "model = PeftModel.from_pretrained(base_model_reload, fine_tuned_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# 💾 Save locally and push to HF Hub\n",
    "model_dir = \"gemma_4b_binary_ver2\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# ☁️ Push to Hugging Face\n",
    "model.push_to_hub(model_dir, use_temp_dir=False)\n",
    "tokenizer.push_to_hub(model_dir, use_temp_dir=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
