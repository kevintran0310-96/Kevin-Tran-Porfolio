{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re # For regular expressions in text preprocessing\n",
    "from nltk.corpus import stopwords # For stopword removal\n",
    "from sklearn.model_selection import train_test_split # For splitting data\n",
    "from sklearn.preprocessing import LabelEncoder # For encoding categorical labels\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # For TF-IDF feature extraction\n",
    "from sklearn import naive_bayes, svm # For Naive Bayes and SVM models\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix # For evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 500\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSONL file\n",
    "file_path = \"DUTA10K_final.jsonl\"\n",
    "df = pd.read_json(file_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop blanks\n",
    "df = df.dropna(subset=[\"text\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower case\n",
    "df[\"text\"] = df[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = df[\"lang\"].unique().tolist()\n",
    "multilingual_stops = set()\n",
    "for lg in langs:\n",
    "    try:\n",
    "        multilingual_stops |= set(stopwords.words(lg))\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess text by removing stopwords\n",
    "def preprocess_multilang(doc):\n",
    "    # basic tokenization\n",
    "    tokens = re.findall(r\"\\b\\w+\\b\", doc.lower())\n",
    "    return \" \".join(w for w in tokens if w not in multilingual_stops) # Join words that are not in the multilingual stopword list\n",
    "\n",
    "# Apply the preprocessing function to the 'text' column to create 'clean_text'\n",
    "df[\"clean_text\"] = df[\"text\"].map(preprocess_multilang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "# X is the cleaned text, y is the original 'category' for multiclass classification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"clean_text\"],\n",
    "    df[\"category\"],\n",
    "    test_size=0.3,\n",
    "    random_state=SEED,\n",
    "    stratify=None  # keep imbalance proportions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical labels to numerical format using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_test_enc  = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(max_features=5000) # Limits the vocabulary size to 5000\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # Fit the TF-IDF vectorizer on the training data and transform it\n",
    "X_test_tfidf  = tfidf.transform(X_test) # Transform the test data using the fitted TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate classic multiclass classification models\n",
    "def evaluate_classic(y_true, y_pred, label_encoder):\n",
    "    \"\"\"\n",
    "    Prints a classification report + confusion matrix only for the\n",
    "    classes actually present in y_true.\n",
    "    \"\"\"\n",
    "    # Which integer labels are in the test set?\n",
    "    present_labels = sorted(set(y_true.tolist()))\n",
    "    \n",
    "    # Map those back to their original names\n",
    "    present_names = [label_encoder.classes_[i] for i in present_labels]\n",
    "\n",
    "    # Print the report for only those classes\n",
    "    print(\"=== Classification Report ===\")\n",
    "    print(classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=present_labels,\n",
    "        target_names=present_names,\n",
    "        zero_division=0,\n",
    "        digits=4\n",
    "    ))\n",
    "\n",
    "    # The corresponding confusion matrix\n",
    "    print(\"=== Confusion Matrix ===\")\n",
    "    print(confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=present_labels\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Naive Bayes model\n",
    "nb = naive_bayes.MultinomialNB()\n",
    "nb.fit(X_train_tfidf, y_train_enc)\n",
    "pred_nb = nb.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report ===\n",
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                                   Art_Music     0.0000    0.0000    0.0000         2\n",
      "                             Casino_Gambling     0.0000    0.0000    0.0000         8\n",
      "                    Counterfeit Credit-Cards     0.8400    0.7368    0.7850        57\n",
      "                           Counterfeit Money     0.0000    0.0000    0.0000        17\n",
      "      Counterfeit Personal-Identification_ID     0.0000    0.0000    0.0000         2\n",
      "Counterfeit Personal-Identification_Passport     0.0000    0.0000    0.0000        10\n",
      "                              Cryptocurrency     0.4178    0.9639    0.5829       166\n",
      "                                Cryptolocker     1.0000    0.9000    0.9474        60\n",
      "                               Drugs_Illegal     0.6875    0.6471    0.6667        68\n",
      "                                 Drugs_Legal     0.0000    0.0000    0.0000         1\n",
      "                               Forum_Illegal     0.0000    0.0000    0.0000         8\n",
      "                                 Forum_Legal     0.7500    0.2400    0.3636        25\n",
      "                                     Hacking     0.0000    0.0000    0.0000        26\n",
      "                           Hosting_Directory     1.0000    0.1500    0.2609        20\n",
      "                        Hosting_File-sharing     0.9500    0.4318    0.5938        44\n",
      "                             Hosting_Folders     0.0000    0.0000    0.0000        22\n",
      "                       Hosting_Search-Engine     0.0000    0.0000    0.0000        11\n",
      "                              Hosting_Server     0.9325    0.8876    0.9095       249\n",
      "                            Hosting_Software     0.8889    0.3000    0.4486        80\n",
      "                           Human-Trafficking     0.0000    0.0000    0.0000         1\n",
      "                                 Leaked-Data     0.0000    0.0000    0.0000         4\n",
      "                               Library_Books     0.0000    0.0000    0.0000         8\n",
      "                         Marketplace_Illegal     0.0000    0.0000    0.0000        23\n",
      "                           Marketplace_Legal     1.0000    0.0417    0.0800        24\n",
      "                                    Personal     0.2383    0.6831    0.3534       142\n",
      "                                    Politics     0.0000    0.0000    0.0000         3\n",
      "                     Porno_Child-pornography     0.0000    0.0000    0.0000        16\n",
      "                   Porno_General-pornography     0.0000    0.0000    0.0000        21\n",
      "                                    Religion     0.0000    0.0000    0.0000         3\n",
      "                            Services_Illegal     0.0000    0.0000    0.0000         1\n",
      "                              Services_Legal     0.0000    0.0000    0.0000        46\n",
      "                         Social-Network_Blog     0.0000    0.0000    0.0000        32\n",
      "                         Social-Network_Chat     0.0000    0.0000    0.0000        18\n",
      "                        Social-Network_Email     0.0000    0.0000    0.0000        18\n",
      "                         Social-Network_News     0.0000    0.0000    0.0000         6\n",
      "                               Violence_Hate     0.0000    0.0000    0.0000         4\n",
      "                             Violence_Hitman     0.0000    0.0000    0.0000         1\n",
      "                            Violence_Weapons     0.0000    0.0000    0.0000         7\n",
      "\n",
      "                                    accuracy                         0.5351      1254\n",
      "                                   macro avg     0.2291    0.1574    0.1577      1254\n",
      "                                weighted avg     0.5308    0.5351    0.4773      1254\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0 42 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "evaluate_classic(y_test_enc, pred_nb, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate Support Vector Machine (SVM) model\n",
    "svm_clf = svm.SVC(C=1.0, kernel=\"linear\", degree=3, gamma=\"auto\", random_state=SEED)\n",
    "svm_clf.fit(X_train_tfidf, y_train_enc)\n",
    "pred_svm = svm_clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- SVM ---\n",
      "=== Classification Report ===\n",
      "                                              precision    recall  f1-score   support\n",
      "\n",
      "                                   Art_Music     0.0000    0.0000    0.0000         2\n",
      "                             Casino_Gambling     1.0000    0.5000    0.6667         8\n",
      "                    Counterfeit Credit-Cards     0.9153    0.9474    0.9310        57\n",
      "                           Counterfeit Money     1.0000    0.7647    0.8667        17\n",
      "      Counterfeit Personal-Identification_ID     0.0000    0.0000    0.0000         2\n",
      "Counterfeit Personal-Identification_Passport     1.0000    0.8000    0.8889        10\n",
      "                              Cryptocurrency     0.9625    0.9277    0.9448       166\n",
      "                                Cryptolocker     1.0000    0.9667    0.9831        60\n",
      "                               Drugs_Illegal     0.6932    0.8971    0.7821        68\n",
      "                                 Drugs_Legal     0.0000    0.0000    0.0000         1\n",
      "                               Forum_Illegal     0.0000    0.0000    0.0000         8\n",
      "                                 Forum_Legal     0.6786    0.7600    0.7170        25\n",
      "                                     Hacking     1.0000    0.5000    0.6667        26\n",
      "                           Hosting_Directory     0.7895    0.7500    0.7692        20\n",
      "                        Hosting_File-sharing     0.8235    0.6364    0.7179        44\n",
      "                             Hosting_Folders     0.6400    0.7273    0.6809        22\n",
      "                       Hosting_Search-Engine     1.0000    0.3636    0.5333        11\n",
      "                              Hosting_Server     0.9913    0.9197    0.9542       249\n",
      "                            Hosting_Software     0.7600    0.4750    0.5846        80\n",
      "                           Human-Trafficking     0.0000    0.0000    0.0000         1\n",
      "                                 Leaked-Data     0.0000    0.0000    0.0000         4\n",
      "                               Library_Books     1.0000    0.1250    0.2222         8\n",
      "                         Marketplace_Illegal     1.0000    0.1739    0.2963        23\n",
      "                           Marketplace_Legal     0.8667    0.5417    0.6667        24\n",
      "                                    Personal     0.3504    0.8662    0.4990       142\n",
      "                                    Politics     0.0000    0.0000    0.0000         3\n",
      "                     Porno_Child-pornography     0.7143    0.3125    0.4348        16\n",
      "                   Porno_General-pornography     0.9231    0.5714    0.7059        21\n",
      "                                    Religion     0.0000    0.0000    0.0000         3\n",
      "                            Services_Illegal     0.0000    0.0000    0.0000         1\n",
      "                              Services_Legal     0.2692    0.1522    0.1944        46\n",
      "                         Social-Network_Blog     0.5333    0.2500    0.3404        32\n",
      "                         Social-Network_Chat     0.4545    0.2778    0.3448        18\n",
      "                        Social-Network_Email     1.0000    0.7778    0.8750        18\n",
      "                         Social-Network_News     0.0000    0.0000    0.0000         6\n",
      "                               Violence_Hate     0.0000    0.0000    0.0000         4\n",
      "                             Violence_Hitman     0.0000    0.0000    0.0000         1\n",
      "                            Violence_Weapons     1.0000    0.2857    0.4444         7\n",
      "\n",
      "                                    accuracy                         0.7241      1254\n",
      "                                   macro avg     0.5622    0.4018    0.4398      1254\n",
      "                                weighted avg     0.7789    0.7241    0.7182      1254\n",
      "\n",
      "=== Confusion Matrix ===\n",
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  4  0 ...  0  0  0]\n",
      " [ 0  0 54 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- SVM ---\")\n",
    "evaluate_classic(y_test_enc, pred_svm, le)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
